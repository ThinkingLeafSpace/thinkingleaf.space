#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›´æ–°åšå®¢åˆ—è¡¨é¡µé¢è„šæœ¬
ä»HTMLæ–‡ä»¶ä¸­æå–æ ‡é¢˜ã€ç®€ä»‹ã€å…³é”®è¯ï¼Œè‡ªåŠ¨æ›´æ–°blogs.htmlå’Œindex.html
"""

import re
import json
from pathlib import Path
from html import unescape
from typing import Dict, List, Optional
from datetime import datetime

# é…ç½®è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
SITE_ROOT = SCRIPT_DIR.parent
BLOGS_DIR = SITE_ROOT / 'blogs'
BLOGS_HTML = SITE_ROOT / 'blogs.html'
INDEX_HTML = SITE_ROOT / 'index.html'


def extract_blog_info(html_file: Path) -> Optional[Dict]:
    """ä»HTMLæ–‡ä»¶ä¸­æå–åšå®¢ä¿¡æ¯"""
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–titleæ ‡ç­¾
        title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
        if not title_match:
            return None
        
        title = title_match.group(1).strip()
        title = title.replace(' - ç­‘å±…æ€', '').strip()
        title = unescape(title)
        
        # æå–description
        desc_match = re.search(r'<meta\s+name=["\']description["\']\s+content=["\'](.*?)["\']', content, re.IGNORECASE)
        description = unescape(desc_match.group(1)) if desc_match else ''
        
        # æå–keywords
        keywords_match = re.search(r'<meta\s+name=["\']keywords["\']\s+content=["\'](.*?)["\']', content, re.IGNORECASE)
        keywords_str = unescape(keywords_match.group(1)) if keywords_match else ''
        keywords = [k.strip() for k in keywords_str.split(',') if k.strip() and k.strip() != 'ç­‘å±…æ€']
        
        # æå–æ—¥æœŸ
        date_match = re.match(r'^(\d{4}-\d{2}-\d{2})', html_file.name)
        date = date_match.group(1) if date_match else None
        
        # æå–é¦–å›¾ï¼ˆçµé­‚å°é¢å›¾ï¼‰- ä¼˜å…ˆæŸ¥æ‰¾ä½ç½®Açš„å®šè°ƒå›¾
        cover_image = None
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª figure > imgï¼ˆä½ç½®Aï¼šçµé­‚å®šè°ƒå›¾ï¼‰
        figure_match = re.search(r'<figure[^>]*>\s*<img[^>]*src=["\']([^"\']+)["\']', content, re.IGNORECASE | re.DOTALL)
        if figure_match:
            cover_image = figure_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰figureï¼ŒæŸ¥æ‰¾ç¬¬ä¸€ä¸ª .post-content img æˆ– article img
            img_match = re.search(r'(?:<div[^>]*class=["\'][^"\']*post-content[^"\']*["\']|article)[^>]*>.*?<img[^>]*src=["\']([^"\']+)["\']', content, re.IGNORECASE | re.DOTALL)
            if img_match:
                cover_image = img_match.group(1)
        
        # è¿‡æ»¤å ä½ç¬¦å›¾ç‰‡å’Œæ— æ•ˆè·¯å¾„
        if cover_image:
            cover_image_lower = cover_image.lower()
            if ('placeholder-image' in cover_image_lower or 
                'placeholder' in cover_image_lower or
                '${date}' in cover_image or
                '${' in cover_image):
                cover_image = None
        
        # è§„èŒƒåŒ–å›¾ç‰‡è·¯å¾„ï¼ˆç›¸å¯¹äºblogs.htmlï¼‰
        if cover_image:
            # å¦‚æœå›¾ç‰‡è·¯å¾„æ˜¯ç›¸å¯¹äºåšå®¢æ–‡ä»¶çš„ï¼ˆ../images/ï¼‰ï¼Œéœ€è¦è½¬æ¢ä¸ºç›¸å¯¹äºblogs.htmlçš„è·¯å¾„
            if cover_image.startswith('../'):
                # ä» blogs/xxx.html åˆ° images/ï¼Œéœ€è¦å»æ‰ ../
                cover_image = cover_image.replace('../', '')
            elif cover_image.startswith('./'):
                cover_image = cover_image.replace('./', '')
            elif not cover_image.startswith('http') and not cover_image.startswith('/'):
                # ç›¸å¯¹è·¯å¾„ï¼Œå‡è®¾æ˜¯ç›¸å¯¹äºåšå®¢æ–‡ä»¶çš„
                cover_image = cover_image
        
        return {
            'filename': html_file.name,
            'title': title,
            'description': description,
            'keywords': keywords,
            'date': date,
            'cover_image': cover_image
        }
    except Exception as e:
        print(f"é”™è¯¯: è¯»å– {html_file.name} å¤±è´¥: {e}")
        return None


def get_all_blogs() -> List[Dict]:
    """è·å–æ‰€æœ‰åšå®¢ä¿¡æ¯ï¼ŒæŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰"""
    blogs = []
    
    for html_file in sorted(BLOGS_DIR.glob('*.html'), reverse=True):
        info = extract_blog_info(html_file)
        if info:
            blogs.append(info)
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    blogs.sort(key=lambda x: x['date'] if x['date'] else '', reverse=True)
    
    return blogs


def escape_html(text: str) -> str:
    """è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦"""
    return (text
            .replace('&', '&amp;')
            .replace('<', '&lt;')
            .replace('>', '&gt;')
            .replace('"', '&quot;')
            .replace("'", '&#39;'))


def update_blogs_html():
    """æ›´æ–°blogs.htmlæ–‡ä»¶"""
    blogs = get_all_blogs()
    
    if not blogs:
        print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°åšå®¢æ–‡ä»¶")
        return
    
    # è¯»å–ç°æœ‰blogs.html
    with open(BLOGS_HTML, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç”Ÿæˆæ–°çš„åšå®¢é“¾æ¥HTML
    # é¦–é¡µé‡æ„ï¼šåªæ˜¾ç¤º"çµé­‚é»„é‡‘ä¸‰è§’"ï¼ˆå°é¢å›¾ã€æ ‡é¢˜ã€å…³é”®è¯æ ‡ç­¾ã€æ—¥æœŸï¼‰
    # ä¸æ˜¾ç¤ºç®€ä»‹æ®µè½ï¼Œé¿å…"è®¤çŸ¥è¿‡è½½"
    blog_links_html = []
    for blog in blogs:
        date_formatted = blog['date'] if blog['date'] else ''
        title_escaped = escape_html(blog['title'])
        keywords_escaped = ', '.join([escape_html(k) for k in blog['keywords'][:8]])  # æœ€å¤šæ˜¾ç¤º8ä¸ªå…³é”®è¯
        
        # ç”Ÿæˆå…³é”®è¯æ ‡ç­¾HTMLï¼ˆä½œä¸º"çµé­‚é»„é‡‘ä¸‰è§’"çš„ä¸€éƒ¨åˆ†ï¼‰
        keywords_html = ''
        if keywords_escaped:
            keywords_html = f'<div class="blog-keywords"><span class="keywords-label">å…³é”®è¯ï¼š</span><span class="keywords-list">{keywords_escaped}</span></div>'
        
        # ç”Ÿæˆå°é¢å›¾HTMLï¼ˆçµé­‚å°é¢å›¾ï¼‰
        cover_html = ''
        if blog.get('cover_image'):
            cover_image_escaped = escape_html(blog['cover_image'])
            cover_html = f'''                                        <div class="blog-cover-wrap">
                                            <img class="blog-cover" src="{cover_image_escaped}" alt="{title_escaped}" loading="lazy">
                                        </div>'''
        
        # é¦–é¡µï¼šæ˜¾ç¤ºå°é¢å›¾ã€æ ‡é¢˜ã€æ—¥æœŸã€å…³é”®è¯ï¼ˆçµé­‚é»„é‡‘ä¸‰è§’ï¼‰
        blog_links_html.append(f'''                                    <a href="blogs/{blog['filename']}" class="link-card">
                                        {cover_html}
                                        <div class="link-content">
                                            <h5>{title_escaped}</h5>
                                            <span class="date-tag">{date_formatted}</span>
                                            {keywords_html}
                                        </div>
                                    </a>''')
    
    # æŸ¥æ‰¾å¹¶æ›¿æ¢åšå®¢é“¾æ¥éƒ¨åˆ†
    # åŒ¹é…ä» <div class="links-grid"> å¼€å§‹åˆ° </div> ç»“æŸï¼ˆä½†è¦åŒ¹é…åˆ°æ­£ç¡®çš„ç»“æŸä½ç½®ï¼‰
    # éœ€è¦åŒ¹é…åˆ° </div></div></div></section> ä¹‹å‰
    pattern = r'(<div class="links-grid">)(.*?)(\s*</div>\s*</div>\s*</div>\s*</section>)'
    
    # ç”Ÿæˆæ›¿æ¢å†…å®¹
    new_links_content = '\n'.join(blog_links_html)
    replacement = r'\1\n' + new_links_content + '\n                                ' + r'\3'
    
    match = re.search(pattern, content, re.DOTALL)
    if match:
        content = re.sub(pattern, replacement, content, flags=re.DOTALL)
        
        # å†™å›æ–‡ä»¶
        with open(BLOGS_HTML, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… å·²æ›´æ–° blogs.htmlï¼Œå…± {len(blogs)} ç¯‡æ–‡ç« ")
    else:
        # å°è¯•æ›´å®½æ¾çš„åŒ¹é…
        pattern2 = r'(<div class="subcategory">\s*<div class="links-grid">)(.*?)(\s*</div>\s*</div>\s*</div>\s*</section>)'
        match2 = re.search(pattern2, content, re.DOTALL)
        if match2:
            content = re.sub(pattern2, replacement, content, flags=re.DOTALL)
            with open(BLOGS_HTML, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… å·²æ›´æ–° blogs.htmlï¼Œå…± {len(blogs)} ç¯‡æ–‡ç« ")
        else:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°åŒ¹é…çš„é“¾æ¥ç½‘æ ¼åŒºåŸŸ")
            print("å°è¯•æŸ¥æ‰¾çš„å†…å®¹:")
            print(repr(content[content.find('<div class="links-grid">'):content.find('<div class="links-grid">')+500]))


def update_index_html():
    """æ›´æ–°index.htmlæ–‡ä»¶ï¼Œåªæ˜¾ç¤ºæœ€æ–°çš„3ç¯‡æ–‡ç« """
    blogs = get_all_blogs()
    
    if not blogs:
        print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°åšå®¢æ–‡ä»¶")
        return
    
    # åªå–æœ€æ–°çš„3ç¯‡
    latest_blogs = blogs[:3]
    
    # è¯»å–ç°æœ‰index.html
    with open(INDEX_HTML, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç”Ÿæˆæ–°çš„åšå®¢å¡ç‰‡HTML
    # é¦–é¡µé‡æ„ï¼šåªæ˜¾ç¤º"çµé­‚é»„é‡‘ä¸‰è§’"ï¼ˆæ ‡é¢˜ã€æ—¥æœŸã€å…³é”®è¯ï¼‰
    # ä¸æ˜¾ç¤ºç®€ä»‹æ®µè½ï¼Œé¿å…"è®¤çŸ¥è¿‡è½½"
    blog_cards_html = []
    for blog in latest_blogs:
        date_formatted = blog['date'] if blog['date'] else ''
        title_escaped = escape_html(blog['title'])
        keywords_escaped = ', '.join([escape_html(k) for k in blog['keywords'][:5]])  # é¦–é¡µæ˜¾ç¤º5ä¸ªå…³é”®è¯
        
        # ç”Ÿæˆå…³é”®è¯æ ‡ç­¾ï¼ˆå¯é€‰æ˜¾ç¤ºï¼‰
        keywords_html = ''
        if keywords_escaped:
            keywords_html = f'<span class="keywords-tags">{keywords_escaped}</span>'
        
        blog_cards_html.append(f'''            <a href="blogs/{blog['filename']}" class="content-card">
              <h4>{title_escaped}</h4>
              <span class="date">{date_formatted}</span>
              {keywords_html}
            </a>''')
    
    # æŸ¥æ‰¾å¹¶æ›¿æ¢åšå®¢éƒ¨åˆ†
    # åŒ¹é…ä» <section class="content-section"> åˆ° </section> çš„åšå®¢éƒ¨åˆ†
    pattern = r'(<section class="content-section">\s*<h3>ğŸ§  æ€ Â· åšå®¢</h3>\s*<div class="content-cards">)(.*?)(\s*</div>\s*</section>)'
    
    # ç”Ÿæˆæ›¿æ¢å†…å®¹
    new_cards_content = '\n'.join(blog_cards_html)
    replacement = r'\1\n' + new_cards_content + '\n          ' + r'\3'
    
    if re.search(pattern, content, re.DOTALL):
        content = re.sub(pattern, replacement, content, flags=re.DOTALL)
        
        # å†™å›æ–‡ä»¶
        with open(INDEX_HTML, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… å·²æ›´æ–° index.htmlï¼Œæ˜¾ç¤ºæœ€æ–°çš„ {len(latest_blogs)} ç¯‡æ–‡ç« ")
    else:
        print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°åŒ¹é…çš„åšå®¢éƒ¨åˆ†")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ›´æ–°åšå®¢åˆ—è¡¨é¡µé¢")
    print("=" * 60)
    print()
    
    if not BLOGS_DIR.exists():
        print(f"âŒ é”™è¯¯: åšå®¢ç›®å½•ä¸å­˜åœ¨: {BLOGS_DIR}")
        return
    
    blogs = get_all_blogs()
    print(f"ğŸ“ æ‰¾åˆ° {len(blogs)} ç¯‡åšå®¢æ–‡ç« ")
    print()
    
    # æ›´æ–°blogs.html
    update_blogs_html()
    
    # æ›´æ–°index.html
    update_index_html()
    
    print()
    print("=" * 60)
    print("æ›´æ–°å®Œæˆï¼")
    print("=" * 60)


if __name__ == '__main__':
    main()

