#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæ­¥åšå®¢å…ƒæ•°æ®è„šæœ¬
ä»Obsidian Markdownæ–‡ä»¶ä¸­è¯»å–titleã€descriptionã€keywordsï¼ŒåŒæ­¥åˆ°HTMLæ–‡ä»¶
å¹¶è‡ªåŠ¨å°†ä¸­æ–‡æ ‡é¢˜è½¬æ¢ä¸ºè‹±æ–‡æ ‡é¢˜
"""

import os
import re
import json
import yaml
from pathlib import Path
from typing import Dict, Optional, Tuple
import sys

# é…ç½®è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
SITE_ROOT = SCRIPT_DIR.parent
BLOGS_DIR = SITE_ROOT / 'blogs'
CONFIG_FILE = SITE_ROOT / 'blog_config.json'
MAPPING_FILE = SCRIPT_DIR / 'title_slug_mapping.json'
TITLE_TRANSLATION_FILE = SCRIPT_DIR / 'title_translation_mapping.json'

# æ’é™¤çš„åšå®¢ï¼ˆä¸è¿›è¡ŒåŒæ­¥ï¼‰
EXCLUDED_BLOGS = [
    "ç­‘å±…æ€ï¼š37å²ï¼Œæˆ‘ç»ˆäºå­¦ä¼šäº†\"å®‰å¿ƒå»ç©\"",
    "37å²ï¼Œæˆ‘ç»ˆäºå­¦ä¼šäº†\"å®‰å¿ƒå»ç©\"",
    "learned-to-play-at-37"
]


def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_title_mapping() -> Dict[str, str]:
    """åŠ è½½æ ‡é¢˜åˆ°slugçš„æ˜ å°„"""
    if MAPPING_FILE.exists():
        with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_title_translation() -> Dict[str, str]:
    """åŠ è½½ä¸­æ–‡æ ‡é¢˜åˆ°è‹±æ–‡æ ‡é¢˜çš„ç¿»è¯‘æ˜ å°„"""
    if TITLE_TRANSLATION_FILE.exists():
        with open(TITLE_TRANSLATION_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_title_translation(mapping: Dict[str, str]):
    """ä¿å­˜ä¸­æ–‡æ ‡é¢˜åˆ°è‹±æ–‡æ ‡é¢˜çš„ç¿»è¯‘æ˜ å°„"""
    with open(TITLE_TRANSLATION_FILE, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)


def translate_chinese_title(chinese_title: str, translation_mapping: Dict[str, str]) -> str:
    """
    å°†ä¸­æ–‡æ ‡é¢˜è½¬æ¢ä¸ºè‹±æ–‡æ ‡é¢˜
    ä¼˜å…ˆä½¿ç”¨æ˜ å°„è¡¨ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•è‡ªåŠ¨ç¿»è¯‘
    """
    # å¦‚æœå·²ç»åœ¨æ˜ å°„è¡¨ä¸­ï¼Œç›´æ¥è¿”å›
    if chinese_title in translation_mapping:
        return translation_mapping[chinese_title]
    
    # å°è¯•ä½¿ç”¨ç¿»è¯‘APIï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    # è¿™é‡Œå…ˆä½¿ç”¨ç®€å•çš„è§„åˆ™ï¼Œåç»­å¯ä»¥é›†æˆç¿»è¯‘API
    # æš‚æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ åˆ°æ˜ å°„è¡¨
    return ""


def extract_front_matter(content: str) -> Tuple[dict, str]:
    """æå–YAML front matter"""
    front_matter = {}
    content_lines = content.split('\n')
    
    if content_lines[0].strip() == '---':
        yaml_lines = []
        i = 1
        while i < len(content_lines) and content_lines[i].strip() != '---':
            yaml_lines.append(content_lines[i])
            i += 1
        
        if i < len(content_lines):
            yaml_content = '\n'.join(yaml_lines)
            try:
                front_matter = yaml.safe_load(yaml_content) or {}
            except Exception as e:
                print(f"  è­¦å‘Š: è§£æYAML front matterå¤±è´¥: {e}")
            remaining_content = '\n'.join(content_lines[i+1:])
            return front_matter, remaining_content
    
    return front_matter, content


def extract_metadata_from_markdown(md_file: Path) -> Optional[dict]:
    """ä»Markdownæ–‡ä»¶ä¸­æå–å…ƒæ•°æ®"""
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        front_matter, _ = extract_front_matter(content)
        
        title = front_matter.get('title', '')
        if isinstance(title, dict):
            title = ''
        title = str(title).strip().strip('"').strip("'")
        
        description = front_matter.get('description', '')
        if isinstance(description, dict):
            description = ''
        description = str(description).strip().strip('"').strip("'")
        
        # categoryä½œä¸ºkeywordsçš„ä¸€éƒ¨åˆ†
        category = front_matter.get('category', [])
        if isinstance(category, str):
            category = [category]
        elif not isinstance(category, list):
            category = []
        
        # keywordså­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰
        keywords_list = front_matter.get('keywords', [])
        if isinstance(keywords_list, str):
            keywords_list = [keywords_list]
        elif not isinstance(keywords_list, list):
            keywords_list = []
        
        # åˆå¹¶categoryå’Œkeywords
        all_keywords = list(set(category + keywords_list))
        
        return {
            'title': title,
            'description': description,
            'keywords': all_keywords
        }
    except Exception as e:
        print(f"  é”™è¯¯: è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
        return None


def find_matching_html_file(title: str, date: str = None) -> Optional[Path]:
    """æ ¹æ®æ ‡é¢˜æŸ¥æ‰¾åŒ¹é…çš„HTMLæ–‡ä»¶"""
    html_files = list(BLOGS_DIR.glob('*.html'))
    
    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…æ ‡é¢˜
    for html_file in html_files:
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # æå–HTMLä¸­çš„æ ‡é¢˜
            title_match = re.search(r'<title[^>]*>(.*?)</title>', html_content, re.IGNORECASE | re.DOTALL)
            if title_match:
                html_title = title_match.group(1).strip()
                html_title = html_title.replace(' - ç­‘å±…æ€', '').strip()
                
                # å¦‚æœæ ‡é¢˜åŒ¹é…ï¼ˆå»é™¤"ç­‘å±…æ€ï¼š"å‰ç¼€ï¼‰
                clean_title = title.replace('ç­‘å±…æ€ï¼š', '').replace('ç­‘å±…æ€Â·', '').strip()
                clean_html_title = html_title.replace('ç­‘å±…æ€ï¼š', '').replace('ç­‘å±…æ€Â·', '').strip()
                
                if clean_title == clean_html_title or title == html_title:
                    return html_file
        except Exception:
            continue
    
    # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ ¹æ®æ—¥æœŸå’Œæ–‡ä»¶ååŒ¹é…
    if date:
        date_prefix = date.replace('-', '-')
        for html_file in html_files:
            if html_file.name.startswith(date_prefix):
                return html_file
    
    return None


def update_html_metadata(html_file: Path, metadata: dict, translation_mapping: Dict[str, str]):
    """æ›´æ–°HTMLæ–‡ä»¶ä¸­çš„å…ƒæ•°æ®"""
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        title = metadata['title']
        description = metadata['description']
        keywords = metadata['keywords']
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if any(excluded in title for excluded in EXCLUDED_BLOGS):
            print(f"  è·³è¿‡ï¼ˆåœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼‰")
            return False
        
        # ç”Ÿæˆè‹±æ–‡æ ‡é¢˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
        english_title = translate_chinese_title(title, translation_mapping)
        if not english_title:
            # å¦‚æœæ²¡æœ‰ç¿»è¯‘ï¼Œä½¿ç”¨ä¸­æ–‡æ ‡é¢˜
            english_title = title
        
        # æ›´æ–°titleæ ‡ç­¾
        title_pattern = r'<title[^>]*>.*?</title>'
        new_title = f'<title>{title} - ç­‘å±…æ€</title>'
        html_content = re.sub(title_pattern, new_title, html_content, flags=re.IGNORECASE | re.DOTALL)
        
        # æ›´æ–°description metaæ ‡ç­¾
        desc_pattern = r'<meta\s+name=["\']description["\']\s+content=["\'][^"\']*["\']\s*/?>'
        new_desc = f'<meta name="description" content="{description}">'
        if re.search(desc_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(desc_pattern, new_desc, html_content, flags=re.IGNORECASE)
        else:
            # å¦‚æœæ²¡æœ‰descriptionæ ‡ç­¾ï¼Œåœ¨titleåé¢æ·»åŠ 
            html_content = re.sub(r'(<title[^>]*>.*?</title>)', r'\1\n    ' + new_desc, html_content, flags=re.IGNORECASE | re.DOTALL)
        
        # æ›´æ–°keywords metaæ ‡ç­¾
        keywords_str = ', '.join(keywords)
        if not keywords_str.endswith('ç­‘å±…æ€'):
            keywords_str += ', ç­‘å±…æ€'
        
        keywords_pattern = r'<meta\s+name=["\']keywords["\']\s+content=["\'][^"\']*["\']\s*/?>'
        new_keywords = f'<meta name="keywords" content="{keywords_str}">'
        if re.search(keywords_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(keywords_pattern, new_keywords, html_content, flags=re.IGNORECASE)
        else:
            # å¦‚æœæ²¡æœ‰keywordsæ ‡ç­¾ï¼Œåœ¨descriptionåé¢æ·»åŠ 
            html_content = re.sub(r'(<meta\s+name=["\']description["\']\s+content=["\'][^"\']*["\']\s*/?>)', r'\1\n    ' + new_keywords, html_content, flags=re.IGNORECASE)
        
        # æ›´æ–°Open Graphå’ŒTwitterå¡ç‰‡
        og_title_pattern = r'<meta\s+property=["\']og:title["\']\s+content=["\'][^"\']*["\']\s*/?>'
        og_desc_pattern = r'<meta\s+property=["\']og:description["\']\s+content=["\'][^"\']*["\']\s*/?>'
        twitter_title_pattern = r'<meta\s+name=["\']twitter:title["\']\s+content=["\'][^"\']*["\']\s*/?>'
        twitter_desc_pattern = r'<meta\s+name=["\']twitter:description["\']\s+content=["\'][^"\']*["\']\s*/?>'
        
        new_og_title = f'<meta property="og:title" content="{title} - ç­‘å±…æ€">'
        new_og_desc = f'<meta property="og:description" content="{description}">'
        new_twitter_title = f'<meta name="twitter:title" content="{title} - ç­‘å±…æ€">'
        new_twitter_desc = f'<meta name="twitter:description" content="{description}">'
        
        if re.search(og_title_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(og_title_pattern, new_og_title, html_content, flags=re.IGNORECASE)
        if re.search(og_desc_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(og_desc_pattern, new_og_desc, html_content, flags=re.IGNORECASE)
        if re.search(twitter_title_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(twitter_title_pattern, new_twitter_title, html_content, flags=re.IGNORECASE)
        if re.search(twitter_desc_pattern, html_content, re.IGNORECASE):
            html_content = re.sub(twitter_desc_pattern, new_twitter_desc, html_content, flags=re.IGNORECASE)
        
        # å†™å›æ–‡ä»¶
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return True
    except Exception as e:
        print(f"  é”™è¯¯: æ›´æ–°HTMLæ–‡ä»¶å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("åšå®¢å…ƒæ•°æ®åŒæ­¥å·¥å…·")
    print("=" * 60)
    print()
    
    # åŠ è½½é…ç½®
    config = load_config()
    obsidian_vault = Path(config.get('obsidian_vault', ''))
    
    if not obsidian_vault.exists():
        print(f"âŒ é”™è¯¯: Obsidianåº“è·¯å¾„ä¸å­˜åœ¨: {obsidian_vault}")
        print("è¯·æ£€æŸ¥ blog_config.json ä¸­çš„ 'obsidian_vault' é…ç½®")
        return
    
    # åŠ è½½æ˜ å°„è¡¨
    translation_mapping = load_title_translation()
    
    # è·å–æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(obsidian_vault.glob('*.md'))
    
    if not md_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•Markdownæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    print()
    
    success_count = 0
    skip_count = 0
    failed_count = 0
    
    for md_file in sorted(md_files):
        print(f"å¤„ç†: {md_file.name}")
        print("-" * 60)
        
        # æå–å…ƒæ•°æ®
        metadata = extract_metadata_from_markdown(md_file)
        if not metadata or not metadata.get('title'):
            print("  è·³è¿‡ï¼ˆæ— æ³•æå–å…ƒæ•°æ®ï¼‰")
            skip_count += 1
            print()
            continue
        
        title = metadata['title']
        description = metadata['description']
        keywords = metadata['keywords']
        
        print(f"  æ ‡é¢˜: {title}")
        print(f"  ç®€ä»‹: {description[:50]}..." if len(description) > 50 else f"  ç®€ä»‹: {description}")
        print(f"  å…³é”®è¯: {', '.join(keywords[:5])}..." if len(keywords) > 5 else f"  å…³é”®è¯: {', '.join(keywords)}")
        
        # æŸ¥æ‰¾åŒ¹é…çš„HTMLæ–‡ä»¶
        # ä»æ–‡ä»¶åæå–æ—¥æœŸ
        date_match = re.match(r'^(\d{4}-\d{2}-\d{2})', md_file.name)
        date = date_match.group(1) if date_match else None
        
        html_file = find_matching_html_file(title, date)
        
        if not html_file:
            print(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°åŒ¹é…çš„HTMLæ–‡ä»¶")
            skip_count += 1
            print()
            continue
        
        print(f"  åŒ¹é…HTML: {html_file.name}")
        
        # æ›´æ–°HTMLæ–‡ä»¶
        if update_html_metadata(html_file, metadata, translation_mapping):
            success_count += 1
            print("  âœ… æˆåŠŸåŒæ­¥")
        else:
            failed_count += 1
            print("  âŒ åŒæ­¥å¤±è´¥")
        
        print()
    
    print("=" * 60)
    print(f"åŒæ­¥å®Œæˆï¼")
    print(f"  æˆåŠŸ: {success_count}")
    print(f"  è·³è¿‡: {skip_count}")
    print(f"  å¤±è´¥: {failed_count}")
    print("=" * 60)
    
    # ä¿å­˜ç¿»è¯‘æ˜ å°„è¡¨
    if translation_mapping:
        save_title_translation(translation_mapping)
        print(f"\nğŸ’¾ å·²ä¿å­˜ç¿»è¯‘æ˜ å°„åˆ°: {TITLE_TRANSLATION_FILE}")


if __name__ == '__main__':
    main()

